---
title: Convergence Analysis of Gradient-Based Learning in Continuous Games
abstract: Considering a class of gradient-based multi-agent learning algorithms in
  non-cooperative settings, we provide convergence guarantees to a neighborhood of
  a stable Nash equilibrium. In particular, we consider continuous games where agents
  learn in 1) deterministic settings with oracle access to their gradient and 2) stochastic
  settings with an unbiased estimator of their gradient. We also study the effects
  of non-uniform learning rates, which causes a distortion of the vector field that
  can alter which equilibrium the agents converge to and the path they take. We support
  the analysis with numerical examples that provide insight into how one might synthesize
  games to achieve desired equilibria.
layout: inproceedings
series: Proceedings of Machine Learning Research
issn: 2640-3498
id: chasnov20a
month: 0
tex_title: Convergence Analysis of Gradient-Based Learning in Continuous Games
firstpage: 935
lastpage: 944
page: 935-944
order: 935
cycles: false
bibtex_author: Chasnov, Benjamin and Ratliff, Lillian and Mazumdar, Eric and Burden,
  Samuel
author:
- given: Benjamin
  family: Chasnov
- given: Lillian
  family: Ratliff
- given: Eric
  family: Mazumdar
- given: Samuel
  family: Burden
date: 2020-08-06
address: 
publisher: PMLR
container-title: Proceedings of The 35th Uncertainty in Artificial Intelligence Conference
volume: '115'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 8
  - 6
pdf: http://proceedings.mlr.press/v115/chasnov20a/chasnov20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v115/chasnov20a/chasnov20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
