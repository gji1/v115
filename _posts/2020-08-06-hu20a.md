---
title: Domain Generalization via Multidomain Discriminant Analysis
abstract: Domain generalization (DG) aims to incorporate knowledge from multiple source
  domains into a single model that could generalize well on unseen target domains.
  This problem is ubiquitous in practice since the distributions of the target data
  may rarely be identical to those of the source data. In this paper, we propose Multidomain
  Discriminant Analysis (MDA) to address DG of classification tasks in general situations.
  MDA learns a domain-invariant feature transformation that aims to achieve appealing
  properties, including a minimal divergence among domains within each class, a maximal
  separability among classes, and overall maximal compactness of all classes. Furthermore,
  we provide the bounds on excess risk and generalization error by learning theory
  analysis. Comprehensive experiments on synthetic and real benchmark datasets demonstrate
  the effectiveness of MDA.
layout: inproceedings
series: Proceedings of Machine Learning Research
issn: 2640-3498
id: hu20a
month: 0
tex_title: Domain Generalization via Multidomain Discriminant Analysis
firstpage: 292
lastpage: 302
page: 292-302
order: 292
cycles: false
bibtex_author: Hu, Shoubo and Zhang, Kun and Chen, Zhitang and Chan, Laiwan
author:
- given: Shoubo
  family: Hu
- given: Kun
  family: Zhang
- given: Zhitang
  family: Chen
- given: Laiwan
  family: Chan
date: 2020-08-06
address: 
publisher: PMLR
container-title: Proceedings of The 35th Uncertainty in Artificial Intelligence Conference
volume: '115'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 8
  - 6
pdf: http://proceedings.mlr.press/v115/hu20a/hu20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v115/hu20a/hu20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
