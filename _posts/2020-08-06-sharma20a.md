---
title: Approximate Relative Value Learning for Average-reward Continuous State MDPs
abstract: In this paper, we propose an approximate relative value learning (ARVL)
  algorithm for non- parametric MDPs with continuous state space and finite actions
  and average reward criterion. It is a sampling based algorithm combined with kernel
  density estimation and function approximation via nearest neighbors. The theoretical
  analysis is done via a random contraction operator framework and stochastic dominance
  argument. This is the first such algorithm for continuous state space MDPs with
  average re- ward criteria with these provable properties which does not require
  any discretization of state space as far as we know. We then evaluate the proposed
  algorithm on a benchmark problem numerically.
layout: inproceedings
series: Proceedings of Machine Learning Research
issn: 2640-3498
id: sharma20a
month: 0
tex_title: Approximate Relative Value Learning for Average-reward Continuous State
  MDPs
firstpage: 956
lastpage: 964
page: 956-964
order: 956
cycles: false
bibtex_author: Sharma, Hiteshi and Jafarnia-Jahromi, Mehdi and Jain, Rahul
author:
- given: Hiteshi
  family: Sharma
- given: Mehdi
  family: Jafarnia-Jahromi
- given: Rahul
  family: Jain
date: 2020-08-06
address: 
publisher: PMLR
container-title: Proceedings of The 35th Uncertainty in Artificial Intelligence Conference
volume: '115'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 8
  - 6
pdf: http://proceedings.mlr.press/v115/sharma20a/sharma20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
