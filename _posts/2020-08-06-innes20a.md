---
title: Learning Factored Markov Decision Processes with Unawareness
abstract: Methods for learning and planning in sequential decision problems often
  assume the learner is aware of all possible states and actions in advance. This
  assumption is sometimes untenable. In this paper, we give a method to learn factored
  markov decision problems from both domain exploration and expert assistance, which
  guarantees convergence to near-optimal behaviour, even when the agent begins unaware
  of factors critical to success. Our experiments show our agent learns optimal behaviour
  on both small and large problems, and that conserving information on discovering
  new possibilities results in faster convergence.
layout: inproceedings
series: Proceedings of Machine Learning Research
issn: 2640-3498
id: innes20a
month: 0
tex_title: Learning Factored Markov Decision Processes with Unawareness
firstpage: 123
lastpage: 133
page: 123-133
order: 123
cycles: false
bibtex_author: Innes, Craig and Lascarides, Alex
author:
- given: Craig
  family: Innes
- given: Alex
  family: Lascarides
date: 2020-08-06
address: 
publisher: PMLR
container-title: Proceedings of The 35th Uncertainty in Artificial Intelligence Conference
volume: '115'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 8
  - 6
pdf: http://proceedings.mlr.press/v115/innes20a/innes20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v115/innes20a/innes20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
