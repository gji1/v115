---
title: Fast Proximal Gradient Descent for A Class of Non-convex and Non-smooth Sparse
  Learning Problems
abstract: Non-convex and non-smooth optimization problems are important for statistics
  and machine learning. However, solving such problems is always challenging. In this
  paper, we propose fast proximal gradient descent based methods to solve a class
  of non-convex and non-smooth sparse learning problems, i.e. the $\ell^0$ regularization
  problems. We prove improved convergence rate of proximal gradient descent on the
  $\ell^0$ regularization problems, and propose two accelerated versions by support
  projection. The proposed accelerated proximal gradient descent methods by support
  projection have convergence rates which match the Nesterovâ€™s optimal convergence
  rate of first-order methods on smooth and convex objective function with Lipschitz
  continuous gradient. Experimental results demonstrate the effectiveness of the proposed
  algorithms. We also propose feedforward neural networks as fast encoders to approximate
  the optimization results generated by the proposed accelerated algorithms.
layout: inproceedings
series: Proceedings of Machine Learning Research
issn: 2640-3498
id: yang20b
month: 0
tex_title: Fast Proximal Gradient Descent for A Class of Non-convex and Non-smooth
  Sparse Learning Problems
firstpage: 1253
lastpage: 1262
page: 1253-1262
order: 1253
cycles: false
bibtex_author: Yang, Yingzhen and Yu, Jiahui
author:
- given: Yingzhen
  family: Yang
- given: Jiahui
  family: Yu
date: 2020-08-06
address: 
publisher: PMLR
container-title: Proceedings of The 35th Uncertainty in Artificial Intelligence Conference
volume: '115'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 8
  - 6
pdf: http://proceedings.mlr.press/v115/yang20b/yang20b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v115/yang20b/yang20b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
